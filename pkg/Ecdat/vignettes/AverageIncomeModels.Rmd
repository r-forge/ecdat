---
title: "Economic impact of presidents and war: Did FDR or WW2 End the Great Depression?"
author: "Spencer Graves and Jouni Helske"
date: "`r Sys.Date()`"
output:
    rmarkdown::html_vignette:
        fig_caption: yes
        fig_width: 6
        fig_height: 5 
vignette: >
  %\VignetteIndexEntry{Average Income Models}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}{inputenc}
---
```{r setup, include = FALSE, cache = FALSE}
library(RefManageR)
bibFile <- system.file("Bib", "biblatexExamples.bib", 
                           package = "RefManageR")
bib <- ReadBib(bibFile, check = FALSE)
bibF2 <- "AvgInc.bib"
bib2 <- ReadBib(bibF2) 
BibOptions(check.entries = FALSE, style = "markdown", cite.style = "authoryear",
           bib.style = "numeric")
```

# Abstract 

Economists claim that World War II (WW2) not Franklin Roosevelt (FDR) ended the Great Depression. U.S. average annual income (Gross Domestic Product, GDP, per capita adjusted for inflation) grew by 10.6 percent per year during WW2 (1939-1945) and only 6.2 percent per year under FDR before the war (1933-1939). If WW2 not FDR ended the Great Depression, we would expect to see (a) similar growth spurts during other wars, and (b) sufficient variability between the economic growth during other presidencies to make FDR's performance consistent with that of other presidents.  We analyze GDP data 1790-2015 with unemployment 1800-2015.  Our findings have implications for both economics and statistical modeling:  (1) We find a president but not a war effect on GDP.  (2) We find a war but not a president effect on unemployment.  (3) The correlation between the state-space increments of the levels of GDP and unemployment was (-1) consistent with Okun's Law.  (4) Nonlinear optimization is still difficult.  Constrained optimizers seemed to give the best results for models where we saw estimation difficulties;  in those cases, we preferred parameterizations in terms of standard deviations and correlations.  

**Key Words**: Kalman filtering and smoothing, KFAS, R (programming language), econometrics, gross domestic product (GDP), unemployment, Okun's Law  

# Introduction 

We begin this article with a brief review of typical perspectives of US economic performance during the Great Depression and World War II.  We then consider a few plots of available data.  That is followed by a summary of models we fit.  This is an interim report on research discussed in a vignette on "Modeling Gross Domestic Product and unemployment with the KFAS package for R" included with the [Ecdat](https://rweb.crmda.ku.edu/cran/web/packages/Ecdat/Ecdat.pdf) package for R, with the most current version available from [R-Forge](https://r-forge.r-project.org/R/?group_id=1439).  

In brief, we do not find growth spurts associated with wars other than WW II, but we do find that major wars have driven down unemployment.  Moreover, the economic growth of the US economy under FDR dramatiacally exceeded that of other presidents. Beyond that we found a correlation of (-1) between state-space increments of the levels of GDP and unemployment, consistent with [Okun's Law](https://en.wikipedia.org/wiki/Okun%27s_law).

For this we use the [KFAS (Kalman filtering and smoothing)](https://rweb.crmda.ku.edu/cran/web/packages/KFAS/KFAS.pdf) package for R.  This work exposed problems using the standard [optim](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/ts.html) nonlinear optimizer for some of our models.  We initially followed the example of the [nlme](https://rweb.crmda.ku.edu/cran/web/packages/nlme/nlme.pdf) package in parameterizing variance parameters on a log scale.  When we perceived problems with that, we tried constrained optimization, parameterizing the problem in terms of standard deviations and correlations, as suggested by `r Citet(bib2, "lme4vignette")`.  In one such case, a standard optim(..., method='L-BFGS-B') call stopped with a negative standard deviation.  That problem was overcome by switching to a different nonlinear optimizer, as suggested by `r Citet(bib2, "lme4vignette")`.  However, our limited tests suggest that the other optimizers may be more fragile than optim(..., method='L-BFGS-B'), and the best strategy may be to parameterize everything on constrained square root and correlation scales, and try at least two different optimizers.  

For average annual income (GDP per capita, adjusted for inflation) we use data from `r Citet(bib2, "MeasuringWorth")`.  For unemployment we used multiple sources, documented with the [USGDPpresidents](https://rweb.crmda.ku.edu/cran/web/packages/Ecdat/USGDPpresidents.pdf) data.frame in the [Ecdat](https://rweb.crmda.ku.edu/cran/web/packages/Ecdat/Ecdat.pdf) package for R.  

# US Economic Performance during the Great Depression and World War II  

The Legacy of the [Great Depression](https://en.wikipedia.org/wiki/Great_Depression) and the [New Deal](https://en.wikipedia.org/wiki/New_Deal) still carry profound implications for the current economic policies of the world's most economically advanced countries.  `r Citet(bib2, "Horowitz2011")` recently claimed that Hoover had more aggressive deficit spending and public works programs than [Franklin Roosevelt (FDR)](https://en.wikipedia.org/wiki/Franklin_D._Roosevelt), and far from contributing to the recovery these programs actually made the economy worse.  He concluded that "The persistence of the Hoover myth continues to justify the counterproductive policies of the Obama administration and thereby prevents markets from generating the economic recovery of which they are fully capable." However, Horowitz's report discusses no model fits, includes no tables, and plots only "real federal spending" from 1929 to 1934.

The dominant view of the evolution of the US economy between 1933 and 1945 is that World War [World War II (WW II)](https://en.wikipedia.org/wiki/Great_Depression#World_War_II_and_recovery), not FDR, ended the [Great Depression](https://en.wikipedia.org/wiki/Great_Depression).  This perspective is supported by our review of the available unemployment data but superficially contradicted by our naive analyses of average annual income in the US ([real US Gross Domestic Product (GDP) per capita](https://en.wikipedia.org/wiki/Real_gross_domestic_product), 1790-2015, from [MeasuringWorth](http://measuringworth.com/)): First, other wars have not been accompanied by such obvious growth spurts. Second, FDR's economic performance even without World War II seems unmatched by any other U.S. president.  

`r Citet(bib2, "McChesney2014")` said, "In earlier eras it had been assumed that there was an economic 'guns and butter' tradeoff, and that military spending had to occur at the expense of other sectors of the economy.  However, one of the lessons of the economic expansion in Nazi Germany, followed by the experience of the United States itself in arming for the Second World War, was that big increases in military spending could act as huge stimulants to the economy." 

Other research identified alternatives that would reportedly produce more jobs than military spending:  Tax cuts for household consumption and increased spending on clean energy, health care and education would produce 27, 47, 69 and 151 percent more jobs, respectively, than military spending, according to `r Citet(bib2, "Pollin2009")`.  

However, these claims are not universally accepted among economists.  `r Citet(bib2, "Barro2013")` cited a dozen different empirical studies that estimated the multiplier effect of military spending.  These studies provide estimates that range from less than zero to roughly 1.4 with a median of 0.6 for those with numbers in Barro's table.  Barro explained that if this multiplier is greater than 1, it means that cuts in defense spending also reduce the private portions of GDP.  If it's positive but less than 1, it means that the private sector increases but by less than the fall in defense.  If it's negative it means that private economic activity rises by more than the fall in defense spending. The work of `r Citet(bib2, "Pollin2009")` suggests that the multiplier effect of a cut in military spending depends on what is done with the defense savings.  

Beyond this, the work of [Milton Friedman](https://en.wikipedia.org/wiki/Milton_Friedman) and others suggests that models like these should also consider [inflation](https://en.wikipedia.org/wiki/Inflation) and [unemployment](https://en.wikipedia.org/wiki/Unemployment);  we consider unemployment but not inflation.    

Whatever the specific cause, the growth of the U.S. economy under [FDR](https://en.wikipedia.org/wiki/Franklin_D._Roosevelt) before the war signficantly exceeds that of any other president (not counting the negative record of [Herbert Hoover](https://en.wikipedia.org/wiki/Herbert_Hoover)).

This document is a summary of research not yet completed but described in detail in a vignette on "Modeling Gross Domestic Product and unemployment with the KFAS package for R" included with the [Ecdat](https://rweb.crmda.ku.edu/cran/web/packages/Ecdat/Ecdat.pdf) package, with the most current version available from [R-Forge](https://r-forge.r-project.org/R/?group_id=1439).    

We used GDP data from `r Citet(bib2, "MeasuringWorth")`, included as the [USGDPpresidents](http://rpackages.ianhowson.com/cran/Ecdat/man/USGDPpresidents.html) data set in the Ecdat package (currently only available in the [R-Forge](https://r-forge.r-project.org/R/?group_id=1439) version of the package).  This [data.frame](https://stat.ethz.ch/R-manual/R-devel/library/base/html/data.frame.html) also includes unemployment data from multiple sources as documented int its help page.  

We have conclusions for both economics and statistical methods:  

    (E1) The models we fit failed to find a signficant effect of war on real GDP per capita but did find that the performance of the U.S. economy under the Hoover and FDR administrations was dramatically different from that for any other presidency. 
  
    (E2) We reach the opposite conclusion from modeling unemployment:  We find a war but not an administration effect.
  
    (E3) We present a state-space version of Okun's law, estimating a correlation of (-1) in the random increments for the state space components representing the levels of unemployment and GDP.  
  
    (E4) These conclusions must be considered tentative, because these models do not consider other variables like inflation that might impact economic growth and unemployment, and our work is still in progress.  
  
    (S1) The companion vignette included with the Ecdat package for R includes several examples of convergence problems using the standard optim numerical optimizer. Most of these came from using unconstrained optimization over log(variance) parameters, following the pattern in the nlme package for R.  When we lacked confidence in the unconstrained optimization, we reparameterized in terms of standard deviations and correlations;  Bates et al. (2014) say that a quadratic will generally approximate the log(likelihood) surface better in that parameterization.  Sadly, we encountered problems also with constrained optimization.  In one case optim(..., method = 'L-BFGS-B') failed while testing parameter values out of bounds.  We fixed this by using an alternative optimizer.  Unfortunately, we have so far not found a single constrained optimizer that seemed to work well for us in all cases.  We're inclined to start with optim(..., method = 'L-BFGS-B') and switch to BOBYQA in the minqa package or Nelder-Mead, BOBYQA, or COBYLA in the nloptr package if we encounter a problem or want to check convergence.  However, this is not based on exhaustive testing.  
    
    (S2) More generally, KFAS provides a powerful set of tools for modeling extensions to the present analysis, e.g., mixing annual and quarterly data or adding other variables such as inflation to our models of GDP per capita with unemployment.

# Initial Plots

We start by plotting the [MeasuringWorth](http://measuringworth.com/) estimates of average annual income in the US (adjusted for inflation) from 1790 to 2015:

```{r, echo=FALSE, fig.cap = "real US GDP per capita (thousands of 2009 $)"}
suppressMessages(library(Ecdat))
GDPna <- is.na(USGDPpresidents$realGDPperCapita)
GDP. <- USGDPpresidents[!GDPna,]
plot(realGDPperCapita/1000~Year, GDP., log='y',
  type='l', ylab='thousands of 2009 dollars', 
  las=1, main='Real US GDP per capita')     
```     

This plot suggests relatively steady growth from 1790 to 2015 with the exception of a dramatic rise roughly two thirds of the way through the series preceded and followed by declines.  

Many readers will likely suspect that this exceptional period corresponds to the [Great Depression](https://en.wikipedia.org/wiki/Great_Depression), [World War II (WW II)](https://en.wikipedia.org/wiki/Great_Depression#World_War_II_and_recovery), and the administrations of [Herbert Hoover](https://en.wikipedia.org/wiki/Herbert_Hoover) and [Franklin Roosevelt (FDR)](https://en.wikipedia.org/wiki/Franklin_D._Roosevelt).  

We now ask the reader:  Can you see in this plot any macroeconomic impact of the First World War, the Civil War or any other war in US history?  

It may be there, but it does not jump at us like the Hoover-FDR period does. To help us evaluate this, we created a variable for war, defined as a violent conflict that averaged over 10 battle deaths per million population per year.  To operationalize that definition, we created variables for approximate battle deaths per year (battleDeaths) and approximate battle deaths per million population per year (battleDeathsPMP).  These varables are included in [USGDPpresidents](http://rpackages.ianhowson.com/cran/Ecdat/man/USGDPpresidents.html).  We plot battleDeathsPMP here with labels for the wars and for the Hoover-FDR period:  

```{r, echo=FALSE, fig.cap = "Battle deaths per million population"}
GDP.$executive <- ordered(GDP.$executive)
GDP.$war <- ordered(GDP.$war)

plotPresWars <- function(x, Data, ..., 
     yHoover=0.8, yFDR=2, yWar=seq(1.7, by=-.1, len=9), 
     cex.war=0.67, lwd.war=1.15, col.war='red'){
  X <- eval(substitute(x), Data)
  plot(X, ...)
  abline(v=c(1929, 1933, 1945), lty='dashed')
  usr <- par('usr')
  Hy <- (usr[3]+yHoover*diff(usr[3:4]))
  if(par('ylog'))Hy <- exp(Hy)
  text(1930, Hy, 'Hoover', srt=90, cex=.9, xpd=NA)
  Ry <- (usr[3]+yFDR*diff(usr[3:4]))
  if(par('ylog'))Ry <- exp(Ry)
  text(1939, Ry, 'FDR', srt=90, cex=1.1, 
       col='blue', xpd=NA)
  yrMid <- mean(usr[1:2])
  dyr <- diff(usr[1:2])
  y. <- seq(usr[3], usr[4], len=5)
  dy <- diff(y.[c(2,4)])
  y2.5 <- mean(y.[c(2,3)])
  wars <- levels(Data$war)
  nWars <- length(wars)
  for(i in 2:nWars){
    w <- wars[i]
    sel <- (Data$war==w)
    yrs <- range(Data$Year[sel])
    abline(v=yrs, lty='dotted', 
           col=col.war, lwd=lwd.war)
    yr. <- mean(yrs)
    wy <- (y2.5 + yWar[i-1]*dy)
    if(par('ylog'))wy <- exp(wy)
    text(yr., wy, w, srt=90, col='red', 
         cex=cex.war, xpd=NA)
  }
  invisible("done")
}

plotPresWars(battleDeathsPMP~Year, GDP., 
    yHoover=0.2, yFDR=.8, 
    yWar=seq(.1, .2, len=9), type='l',
     ylab='battle deaths per million pop', las=1, 
     main='Battle deaths during war')     
```     

The 2001-2014 [War in Afghanistan](https://en.wikipedia.org/wiki/War_in_Afghanistan_(2001%E2%80%9314)) and the 2003-2011 [Iraq war](https://en.wikipedia.org/wiki/Iraq_War) do not appear here, because together they averaged fewer than 3 battle deaths per year per million population.  One might argue that they were more like the [Super Bowl](https://en.wikipedia.org/wiki/Super_Bowl) than World War II in terms of their impact on the U.S. economy.  

We also model unemployement, with numbers taken from four different sources as documented in [help(USGDPpresidents)](http://rpackages.ianhowson.com/cran/Ecdat/man/USGDPpresidents.html):  

```{r, echo=FALSE, fig.cap = "Presidents, wars & unemployment"}
GDP <- GDP.
GDP$realGDPperCapita <- ts(GDP$realGDPperCapita, 
                             GDP$Year[1])
GDP$unemployment <- ts(GDP$unemployment, 
                             GDP$Year[1])
plotPresWars(unemployment, GDP, 
             main=paste0('US unemployment'), 
             ylab='unemployment rate', las=1, 
             xlab='', yHoover=0.07, yFDR=0.25, 
             yWar=seq(.5, by=-.05, len=9)) 
```

The unemployment numbers prior to 1890 clearly do not track the state of the economy as well as the more recent data.  More to the point of the present discussion, the unemployment climbed almost vertically during the Hoover years and fell dramatically during the administration of FDR.  Closer study suggests that unemployment fell rapidly during all wars for which we have reasonable data except for Vietnam.  It's less clear from this image if unemployment fell more rapidly during FDR but prior to World War II than it has under other presidencies.  We need models for that -- and, as noted elsewhere in this report, the models did not support an exceptional FDR effect on unemployment.

# Choice of scales 

We model income data on a log scale, consistent with the above plot of realGDPperCapita.  

We model unemployment on a probit scale for multiple reasons:  First, simple logic says that nothing can be truely normally disributed if the numbers must be bounded, e.g., all positive like variances or between 0 and 1 like correlations.  Second, the [Shapiro-Wilks](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/formula.html) test for normality of first differences of the raw unemployment numbers since 1890 vs. log, logit and probit transformations gave significance probabilities of 5e-5, 4e-5, 6e-5 and 1e-4:  The increments on none of these scales are independent normal with constant variance.  However, the numbers come from different sources, and our best models for unemployment included estimated 3 levels of observation error variance, with the older data being less reliable, as we might expect.   Finally, the probit has the additional interpretation of an accumulation of many small additive adjustments, which should make the result normal in most cases by the [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem).  

To look at the difference, we redo here the above plot of unemployment:  

```{r, echo=FALSE, fig.cap = "Presidents, wars & probit(unemployment)"}
plotPresWars(qnorm(unemployment), GDP, 
    main=paste0('US unemployment'), 
    ylab='unemployment rate', las=1, xlab='',
    yHoover=0.07, yFDR=0.25, 
    yWar=seq(.5, by=-.05, len=9), axes=FALSE) 
axis(1)
unempScale <- c(.02, .05, .1, .2)
axis(2, qnorm(unempScale), unempScale)
```

The dramatic nature of the impact of World War II is more visible in this plot than in the above plot of the untransformed data.  We think most serious observers would agree that it's more difficult to reduce unemployment from 2 percent to 1.2 percent (the lowest level recorded) than from 10 percent to 9 percent, for example.  Use of this transformed scale provides an automatic acknowledgement of that increased difficulty.  
[USGDPpresidents](https://rweb.crmda.ku.edu/cran/web/packages/Ecdat/USGDPpresidents.pdf) includes a variable, "unempSource" indicating the source of the numbers used here.  This is an ordered factor, and we can order a count of observations by its levels:  

```{r echo=FALSE, unempSource}
(unempS <- table(GDP$unempSource))
```

The help page for USGDPpresidents says that Lebergott is the source for the data until 1890, and Romer's data are used through 1930.  The current standard source, [the US Bureau of Labor Statistics (BLS)](https://en.wikipedia.org/wiki/Bureau_of_Labor_Statistics), has data starting in 1940.  

Economists also claim that low unemployment tends increase [inflation](https://en.wikipedia.org/wiki/Inflation), a relationship called the [Phillips curve](https://en.wikipedia.org/wiki/Phillips_curve).  [Another reason for using a transformation like probits, i.e., qnorm(unemployment), is that it might tend to linearize the "curve" that `r Citet(bib2, "Philips")` observed in unemployment in the [United Kingdom](https://en.wikipedia.org/wiki/United_Kingdom) from 1913 to 1948.)  

Inflation is widely calculated from changes in a price index, usually the consumer price index.  The CPI is included in the GDP data.frame, but we'll skip that for the present discussion.  

We next briefly outline the general Kalman framework.  This is followed by an overview of the alternative models fit so far in the companion vignette included in the [Ecdat](https://rweb.crmda.ku.edu/cran/web/packages/Ecdat/Ecdat.pdf) package for R.  This article ends with a brief discussion of future work in this area.  

# Kalman Filtering and Smoothing 

The theory behind these models can be described in terms of a 3-step Bayesian updating cycle to add new observations to a probability distribution summarizing the available knowledge about the state of the system under study `r AutoCite(bib2, "Graves07")`:

  1.  Receive and store new data.  
  
  1.  Create a prior distribution for the new data by modifying the posterior computed after the last observation to allow for possible changes in state in the time between the last and current observations.    
  
  1.  Combine the new data with the prior to produce a posterior distribution of the state.  
  
Three different names are commonly used for this class of models.  The oldest name is 'Kalman filtering (and smooting)', recognizing the path-breaking contributions of [Rudolf E. Kálmán](https://en.wikipedia.org/wiki/Rudolf_E._K%C3%A1lm%C3%A1n).  A more descriptive term for this class of models is "state space", recognizing the central role of the indirectly observed "state" in these models;  this term is used by `r Citet(bib2, "DurbinKoopman")`.  `r Citet(bib2, "West97")` call these "Dynamic (linear) models."

In the present discussion, the system under study is the US economy at various times, which we will summarize in a vector of one or more numbers that represent the state or condition of the economy at each point in time.  (The term "state" in "state space" refers to this type of representation.)  The data will be annual observations on real US GDP per capita (realGDPperCapita) and / or unemployment, as previously discussed.    

Our primary reference for Kalman filtering is `r Citet(bib2, "DurbinKoopman2")`.  In brief, we assume that time series observations $y_t$, $t$ = 1, 2, ..., are linear functions of some latent state vector,  $\alpha_t$, plus observation error:  

$$y_t = Z_t \alpha_t + \epsilon_t$$

$$\alpha_{t+1} = T_t \alpha_t + R_t \eta_t.$$

where $\epsilon_t \tilde\ N(0, H_t)$, $\eta_t \tilde\ N(0, Q_t)$ and $\alpha_1 \tilde\ N(a_1, P_1)$, independent of each other.  In this, $y_t$ is a $p$-vector (where $p$ may actually vary with $t$), $\alpha_t$ is $m$-dimensional, and $\eta_t$ has dimension $k$.  (See `r Citet(bib2, "DurbinKoopman")` for more detail on the theory behind this model or `r Citet(bib2, "KFASarticle")` for more on the KFAS implementation.)   

The first of these two equations is called the "observtion equation".  The second is called the "state transition equation".  When a new observation arrives, we first degrade the posterior from the previous observation to obtain a prior for the new observation to model the loss of knowledge about the state by the addition of migration noise per the state transition equation.  Then we apply Bayes' theorem to get a new observation, as outlined with the 3-step cycle above.  This is Kalman filtering.  Kalman smoothing then runs time backward using similar math to produce posterior estimates of the state at each point in time given all the data, not just the previous data.  

In the models considered here, $y_t$ is log(realGDPperCapita) or qnorm(unemployment) or both. The dimensionality of $\alpha_t$ will vary, but the first component(s) will always be the level.  With a univariate response, $Z_t$ will be a row vector with 1 in the first position and 0 elsewhere. With a bivariate respose, $Z_t$ will have two rows, with the first two columns being an identity matrix and the rest being zero.  

This will force $Q_t$, $T_t$, and $P_1$ to change between models.  In addition, some models have diffuse initialization for the state vector.  These are specified by a model component $P_{1,\infty}$;  see `r Citet(bib2, "KFASarticle")` or [SSmodel](http://rpackages.ianhowson.com/cran/KFAS/man/logLik.SSModel.html).  

And the different models require estimating different parameters.  These pieces are summarized in the following table:  

  || Response | Model | state vector compo- nents | time-varying compo-nents | P1 | P1inf | parameters to estimate 
-:|:-----|------------------|:-----|:----:|:---:|:---:|:--------------
1 | GDP/cap | EWMA1: Standard Bayesian EWMA | 1:level | | 0 | 1 | 2:Q, H
2 | GDP/cap | EWMA2: double EWMA | 2:level, slope | | 0 | diag(2) | 3:Q.lvl, Q.slope, H
 | | | | | | | |  
3 | GDP/cap | EWMA2pres1: EWMA2 allowing slope to change only between presidents | 2:level, slope | Q | 0 | diag(2) | 3:Q.lvl, Q.slope, H 
4 | GDP/cap | EWMA2pres2: EWMA2 estimating mean slope and no continuity between presidents | 3:level, slope, a1.slope | T, Q | diag(c(0, NA, 0)) | diag(c(1, 0, 0)) | 4:a1.slope, Q.lvl, Q.slope, H
5 | GDP/cap | EWMA2pres3: EWMA2 with an adjustment for each president | 3:level, slope, pres3 | T, Q | diag(c(0, 0, NA) | diag(c(1, 1, 0)) | 4:Q.lvl, Q.slope, Q.pres3, H 
 | | | | | | | |  
6 | GDP/cap | EWMA2war0: EWMA2 with fixed effect of war | 4:level, slope, war, deaths | T | 0 | diag(4) | 3:Q.lvl, Q.slope, H
7 | GDP/cap | EWMA2war1: EWMA2 with random effect of war | 4:level, slope, war, deaths | T, Q | diag(c(0, 0, Q.war))	| diag(c(1, 1, 0, 0)) | 6:Q.lvl, Q.slope, Q.war, Q.deaths, Q.warDeaths, H
8 | GDP/cap | EWMA2war2: EWMA2 with variance effect for war |	2:level, slope |	Q |	0 | diag(2) | 5:Q.lvl, Q.slope, Q.war, Q.deaths, H
 | | | | | | | |  
9 | unemp | uEWMA1: Standard Bayesian EWMA | 1:level | | 0 | 1 | 2:Q, H
10 | unemp | uEWMA1a: EWMA with higher error variance for older data | 1:level | H | 0 | 1 | 5:Q, H1..4 
 | | | | | | | | | 
11 | unemp | uEWMA1pres3: EWMA with a slope adjustment for each president | 2:level, pres3 | T, Q, H | diag(c(0, NA)) | diag(c(1, 0)) | 6:Q.lvl, Q.pres3, H1..4
12 | unemp | uEWMA1war0: EWMA with fixed slope adjustments for war | 3:level, war, deaths | T, H | 0                 | diag(3)          | 5:Q.lvl, H1..4 
13 | unemp | uEWMA1war1: EWMA with radom slope adjustments for war            | 3:level, war, deaths        | T, Q, H | diag(c(0, Q.war))      | diag(3)             | 8:Q.lvl, Q.war, Q.deaths, Q.warDeaths, H1..4 
 | | | | | | | | | 
14 | GDP/cap & unemp | Okun: [Okun's law](https://en.wikipedia.org/wiki/Okun's_law) | 3:GDP.lvl, unemp.lvl, GDP.slope | H | 0 | diag(3) | 10:Q.pl, Q.ul, Q.ps, Q.pl.ul, Q.ul.ps, Hp, Hu1..4 

We will limit the discussion in this interim report to these models.  We expect, however, that fitting other similar models would likely support a deeper understanding of the macroeconomic impact of presidents and wars.   

Details of the exact structure of the matrices in each model are available in companion vignette included in the [Ecdat](https://rweb.crmda.ku.edu/cran/web/packages/Ecdat/Ecdat.pdf) package for R.  

The following table summarizes the fit obtained from these models starting with the number of degrees of freedom with the estimated marginal likelihood and the root mean square prediction errors for each model.  The number of degrees of freedom is the number of parameters estimated by nonlinear iteration plus the number of diffuse states;  the latter is obtained as sum($P_{1,\infty}$), since $P_{1,\infty}$ is a 0-1 matrix with 1's on the diagonal for each state with a diffuse prior.  The table also includes columns summarizing whether the nonlinear estimation seemed to converge when parameterized in terms of log(variances) [logScale = y or n] and whether a constrained optimization was attempted and if so, whether it returned an error code or returned the best fit ("failed" vs. y or n;  "-" if not attempted):  

```{r, echo=FALSE}
suppressMessages(library(KFAS))
EWMA1fmla <- log(realGDPperCapita)~
  SSMtrend(1,Q=list(matrix(NA)), a1=log(realGDPperCapita[1]),
           ynames='lnGDPperCap')
#We use this to create an SSModel as follows:  
EWMA1mdl <-SSModel(EWMA1fmla, GDP, H=matrix(NA) )
# This model has 2 unknowns, 
#     the NA's in EWMA1fmla and SSModel: Q & H  

EWMA1fit <- fitSSM(EWMA1mdl, inits=c(lnQ=0, lnH=0))

EWMA1pred <- predict(EWMA1fit$model, 
    interval='prediction', filtered=TRUE)

EWMA1fitM <- fitSSM(EWMA1mdl, 
    inits=EWMA1fit$optim.out$par, marginal=TRUE)
#EWMA1fit$optim.out$par
#EWMA1fitM$optim.out$par
#logLik(EWMA1fit$model)
#logLik(EWMA1fitM$model, marginal=TRUE)

EWMA1.KFS <- KFS(EWMA1fit$model)
nInf <- length(EWMA1.KFS$Finf)
N <- nrow(EWMA1.KFS$model$y)
i. <- (nInf+1):N
#-0.5*with(EWMA1.KFS, sum(log(Finf)) + #(N-nInf)*log(2*pi) +
#            sum(log(F[i.]) + v[i.]^2/F[i.]) )
#sqrt(mean(EWMA1.KFS$v^2))

#Let's wrap these three goodness-of-fit measures 
#   in a fuction ... 
logLik2 <- function(object, ...){
  ll2 <- data.frame(ndf=NA, diffuse=NA, 
      marginal=NA, rmse.lnUSD=NA, 
      rmse.pbtUnemp=NA, 
      stringsAsFactors=FALSE)
  ll2[1] <- (length(object$optim.out$par)
             + sum(object$model$P1inf) )
  ll2[2] <- logLik(object$model)
  ll2[3] <- logLik(object$model, marginal=TRUE)
  K. <- KFS(object$model)
  Ks <- apply(K.$v^2, 2, function(x)
        sqrt(mean(x, na.rm=TRUE)))
  if(length(Ks)<2){
    Ynames <- colnames(object$model$y)
    if((!is.null(Ynames)) && (Ynames=='probitUnemp')){
      ll2[5] <- Ks
    } else ll2[4] <- Ks
  } else ll2[4:5] <- Ks
#
  ll2
}
#data.frame to store these numbers 
#   for the different models we'll fit:  

mdls <- c('EWMA1', 'EWMA2', 'EWMA2pres1', 
   'EWMA2pres2', 'EWMA2pres3', 'EWMA2war0',
   'EWMA2war1', 'EWMA2war2', 'uEWMA1', 'uEWMA1a', 
   'uEWMA1pres3', 'uEWMA1war0', 'uEWMA1war1',
   'Okun')
n.mdls <- length(mdls)
logLiks <- data.frame(model=mdls, 
    ndf=rep(NA, n.mdls), diffuse=rep(NA, n.mdls),
    marginal=rep(NA, n.mdls), 
    rmse.lnUSD=rep(NA, n.mdls), 
    rmse.pbtUnemp=rep(NA, n.mdls), 
    logScale=character(n.mdls), 
    constr=character(n.mdls), 
    reference=character(n.mdls), 
    p.value=character(n.mdls), 
    row.names=1:n.mdls, stringsAsFactors=FALSE)
#
logLiks[1, 2:6] <- logLik2(EWMA1fit)
logLiks[1, 7:8] <- c('y', '-')

#EWMA1.rstd <- rstandard(EWMA1.KFS)

depr1 <- with(GDP, (1927<=Year) & (Year <= 1948))
#GDP[depr1, c('Year', 'realGDPperCapita')]

depr <- with(GDP, (1929<=Year)&(Year<=1947))
EWMA1mdl.woDepr <- EWMA1mdl
EWMA1mdl.woDepr$y[depr] <- NA
EWMA1.woDeprFit<-fitSSM(EWMA1mdl.woDepr, 
                         inits=c(lnQ=0, lnH=0))
EWMA1.woDeprPred <- predict(EWMA1.woDeprFit$model, 
              interval='prediction', filtered=TRUE)

# EWMA2:  

a1.2 <- c(level=log(GDP$realGDPperCapita[1]), slope=0)
EWMA2fmla <- log(realGDPperCapita)~
  SSMtrend(2,Q=list(Q.lvl=matrix(NA), Q.slope=matrix(NA)), 
           a1=a1.2, ynames='lnGDPperCap')

EWMA2mdl <-SSModel(EWMA2fmla, GDP, H=matrix(NA))

EWMA2init <- c(lnQ.lvl=0, lnQ.slope=0, lnH=0)
EWMA2fit<-fitSSM(EWMA2mdl, inits=EWMA2init)

logLiks[2,  2:6] <- logLik2(EWMA2fit)
logLiks[2, 7:9] <- c('y', '-', 'EWMA1')
logLR2 <- apply(logLiks[1:2, 2:4], 2, diff)
logLiks[2, 10] <- signif(pchisq(2*logLR2[3], 2, 
                         lower=FALSE), 2)

EWMA2.KFS <- KFS(EWMA2fit$model)

EWMA2pres1Q.slope <- array(0, c(1,1,N), 
      dimnames=list('slope', 'slope', GDP$Year))
contin <- duplicated(GDP$executive)
presLastYr <- c(!contin[-1], FALSE)
EWMA2pres1Q.slope[,,presLastYr] <- NA 

EWMA2pres1fmla <- log(realGDPperCapita) ~ 
  SSMtrend(2, Q = list(lnQ.lvl=matrix(NA), 
              lnQ.slope=EWMA2pres1Q.slope), a1=a1.2,
           ynames='lnGDPperCap') 

EWMA2pres1mdl <-SSModel(EWMA2pres1fmla, GDP,
                        H=matrix(NA))

EWMA2pres1updt <- function(pars=EWMA2init,
              model=EWMA2pres1mdl, ...){
  vars <- exp(pars)
  Q <- model$Q
  Q[1,1,] <- vars[1]
  Q[2,2,presLastYr] <- vars[2]
  model$Q <- Q
  model$H[] <- vars[3]
  model
} 

EWMA2pres1fit <- fitSSM(EWMA2pres1mdl, 
      inits=EWMA2init, updatefn=EWMA2pres1updt)

logLiks[3, 2:6] <- logLik2(EWMA2pres1fit)

logLiks[3, 7:9] <- c('y', '-', 'EWMA2')
logLR2p1 <- apply(logLiks[2:3, 2:4], 2, diff)
logLiks[3, 10] <- 1

EWMA2init2 <- exp(EWMA2init)
names(EWMA2init2) <- c('Q.lvl', 'Q.slope', 'H')
EWMA2pres1updt2 <- function(pars=EWMA2init2,
              model=EWMA2pres1mdl, ...){
  Q <- model$Q
  Q[1,1,] <- pars[1]
  Q[2,2,presLastYr] <- pars[2]
  model$Q <- Q
  model$H[] <- pars[3]
  model
} 
```

line 411

```{r, echo=FALSE}
EWMA2pres1fit2 <- fitSSM(EWMA2pres1mdl,
    inits=EWMA2init2, updatefn=EWMA2pres1updt2,  
    method = "L-BFGS-B", lower=rep(0, 3), 
    upper=rep(Inf, 3))
#EWMA2pres1fit2$optim.out
#EWMA2pres1fit$optim.out
logLiks[3, 8] <- 'failed'

EWMA2p1init <- exp(EWMA2pres1fit$optim.out$par)
names(EWMA2p1init) <- c('Q.lvl', 'Q.slope', 'H')
#EWMA2p1init
EWMA2pres1fit2a <- fitSSM(EWMA2pres1mdl,
    inits=EWMA2p1init, updatefn=EWMA2pres1updt2,  
    method = "L-BFGS-B", lower=rep(0, 3), 
    upper=rep(Inf, 3))
#EWMA2pres1fit2a$optim.out
#This stopped where it started with an #ABNORMAL_TERMINATION_IN_LNSRCH -- but without 
#violating the lower bound as before.  

likfn <- function(pars=EWMA2init2, model=EWMA2pres1mdl, 
                  updatefn=EWMA2pres1updt2) {
    Model <- do.call(updatefn, args = 
                       list(pars, model))
    (-logLik(object = Model, check.model = FALSE))
}
#likfn()
#likfn(EWMA2p1init)

suppressMessages(library(minqa))
EWMA2pres1fit2a <- bobyqa(EWMA2init2, likfn, 
        lower=rep(0, 3), model=EWMA2pres1mdl, 
        updatefn=EWMA2pres1updt2)
# This stopped with Objective = (-272.68),
# substantially larger than the previous min 
# of (-386.91).  
# Let's try starting with the previous best:  
EWMA2pres1fit2b <- bobyqa(EWMA2p1init, likfn, 
        lower=rep(0, 3), model=EWMA2pres1mdl, 
        updatefn=EWMA2pres1updt2)
#This put Q.slope = H = 0, their lower bounds, 
# and essentially no change in the objective function. # Let's try nloptr: 
suppressMessages(library(nloptr))
EWMA2pres1fit2c <- suppressWarnings(
  nloptr(EWMA2init2, likfn, 
        lb=rep(0, 3), 
        opts=list(algorithm='NLOPT_LN_BOBYQA'), 
        model=EWMA2pres1mdl, updatefn=EWMA2pres1updt2))
EWMA2pres1fit2d <- suppressWarnings(
  nloptr(EWMA2p1init, likfn,
        lb=rep(0, 3), 
        opts=list(algorithm='NLOPT_LN_BOBYQA'), 
        model=EWMA2pres1mdl, updatefn=EWMA2pres1updt2))

EWMA2pres1fit2e <- suppressWarnings(
  nloptr(EWMA2init2, likfn, 
        lb=rep(0, 3), 
        opts=list(algorithm='NLOPT_LN_NELDERMEAD'), 
        model=EWMA2pres1mdl, updatefn=EWMA2pres1updt2))
EWMA2pres1fit2f <- suppressWarnings(
  nloptr(EWMA2p1init, likfn,
        lb=rep(0, 3), 
        opts=list(algorithm='NLOPT_LN_NELDERMEAD'), 
        model=EWMA2pres1mdl, updatefn=EWMA2pres1updt2))
#Conclusion:  We got convergence 
# when we gave the answer but not when we didn't.  
# That doesn't help.  
```

line 478 after nloptr

```{r, echo=FALSE}
#compute the smoothed estimate of the state vector,
#because we use it in the next model:  
EWMA2pres1.KFS <- KFS(EWMA2pres1fit$model)
# 4.  Assuming no continuity in slope 
# between executives 

a1.3 <- c(level=log(GDP$realGDPperCapita[1]), 
           slope=NA, a1.slope=NA)
EWMA2pres2.P1inf <- diag(c(1,0,0))
dimnames(EWMA2pres2.P1inf) <- list(names(a1.3),
                                   names(a1.3))
EWMA2pres2.P1 <- EWMA2pres2.P1inf
EWMA2pres2.P1[1,1] <- 0
EWMA2pres2.P1[2,2] <- NA
EWMA2pres2fmla <- log(realGDPperCapita)~
  SSMtrend(3,Q=list(Q.lvl=matrix(NA),
                    Q.slope=EWMA2pres1Q.slope, 
                    Q.a1.slope=matrix(0)), 
           a1=a1.3, P1=EWMA2pres2.P1, 
           P1inf=EWMA2pres2.P1inf, 
           ynames='lnGDPperCap')

EWMA2pres2mdl. <-SSModel(EWMA2pres2fmla, GDP,
                         H=matrix(NA))

fixModelNames <- function(model, stateNames, 
                          yNames){
  mdl <- model 
  if(missing(yNames)){
    yNames <- colnames(mdl$y)
    if(is.null(yNames)) {
      yNames <- dimnames(mdl$Z)[[1]]
    }
  }
  colnames(mdl$y) <- yNames
  mdlTime <- time(mdl$y)
  n <- attr(mdl, 'n')
  if(length(mdlTime)<n){
    mdlTime <- dimnames(mdl$T)[[3]]
    if(length(mdlTime)<n){
      mdlTime <- dimnames(mdl$Q)
      if(length(mdlTime)<n){
        mdlTime <- dimnames(mdl$H)
        if(length(mdlTime)<n){
          mdlTime <- 1:n
        }
      }
    }
  }
# Z
  if(dim(mdl$Z)[3]>1){
    dimnames(mdl$Z) <- list(yNames, stateNames, 
                            mdlTime)
  } else {
    dimnames(mdl$Z) <- list(yNames, stateNames, NULL)
  }
# H
  if(dim(mdl$H)[3]>1){
    dimnames(mdl$H) <- list(yNames, yNames, 
                            mdlTime)
  } else {
    dimnames(mdl$H) <- list(yNames, yNames, NULL)
  }
# T   
  if(dim(mdl$T)[3]>1){
    dimnames(mdl$T) <- list(stateNames, stateNames, 
                            mdlTime)
  } else {
    dimnames(mdl$T) <- list(stateNames, stateNames,
                            NULL)
  }
# R  
  if(dim(mdl$R)[3]>1){
    dimnames(mdl$R) <- list(stateNames, stateNames, 
                            mdlTime)
  } else {
    dimnames(mdl$R) <- list(stateNames, stateNames,
                            NULL)
  }
# Q  
  if(dim(mdl$Q)[3]>1){
    dimnames(mdl$Q) <- list(stateNames, stateNames, 
                            mdlTime)
  } else {
    dimnames(mdl$Q) <- list(stateNames, stateNames,
                            NULL)
  }
# a1, P1, P1inf 
  dimnames(mdl$a1)[[1]] <- stateNames 
  dimnames(mdl$P1) <- list(stateNames, stateNames)
  dimnames(mdl$P1inf) <- list(stateNames, stateNames)
#
  mdl 
}
EWMA2pres2mdl <- fixModelNames(EWMA2pres2mdl., 
            names(a1.3), 'logGDPperCapita' )
```

line 583 after fixModelNames

```{r, echo=FALSE}
T3.other <- EWMA2pres2mdl$T
EWMA2pres2.T <- array(T3.other, c(3,3,N), 
      dimnames=dimnames(T3.other))
dimnames(EWMA2pres2.T)[[3]] <- GDP$Year
EWMA2pres2.T[2,2,presLastYr] <- 0
EWMA2pres2.T[2,3,] <- presLastYr

EWMA2pres2mdl$T <- EWMA2pres2.T

attr(EWMA2pres2mdl, 'tv') <- c(Z=0L, H=0L, 
                        T=1L, R=0L, Q=1L)

EWMA2pres2.a1.2 <- mean(EWMA2pres1.KFS$alphahat[,2])

#EWMA2pres1fit$optim.out$par
#exp(EWMA2pres1fit$optim.out$par/2)

EWMA2pres2init <- c(a1.2=EWMA2pres2.a1.2,
        EWMA2pres1fit$optim.out$par)
EWMA2pres2init[3:4] <- EWMA2pres2init[2]
#EWMA2pres2init

EWMA2pres2updt <- function(pars=EWMA2pres2init, 
                      model=EWMA2pres2mdl, ...){
#  a1 
  model$a1[2:3] <- pars[1]
#  Q  
  vars <- exp(pars[-1])
  Q <- model$Q
  Q[1,1,] <- vars[1]
  Q[2,2,presLastYr] <- vars[2]
  model$Q <- Q
# P1 
  model$P1[2,2] <- vars[2]
# H   
  model$H[] <- vars[3]
  model
} 

EWMA2pres2fit <- fitSSM(EWMA2pres2mdl, 
          inits=EWMA2pres2init,
          updatefn=EWMA2pres2updt) 

logLiks[4, 2:6] <- logLik2(EWMA2pres2fit)

logLiks[4, 7:9] <- c('y', '-', 'EWMA2')
logLR2p2 <- apply(logLiks[c(2,4), 2:4], 2, diff)
logLiks[4, 10] <- 'significant'

#logLiks[1:4,]

EWMA2pres2.KFS <- KFS(EWMA2pres2fit$model)

stateByFactor <- function(object, state='slope', 
              factor.=GDP$executive, cor.=1, 
              conf=0.95, factorName='president'){
# object has has components alphahat and V, 
#    because it is assumed to be of class KFS   
# mean state 
  stateNames <- colnames(object$alphahat)
  if(is.null(stateNames)){
    stop('alphahat needs colnames; absent')
  } 
  ist <- which(colnames(object$alphahat) == state)
  if(length(ist) != 1){
    stop('state = ', state, ' not found in ', 
         'colnames(alphahat) = ', 
         paste(stateNames, collapse=', '))
  }
#
  meanState <- mean(object$alphahat[, state])
  facState <- tapply(object$alphahat[, state], 
                      factor., mean)
  nSt <- length(facState)
# If the correlations are all 1, the standard deviation 
# of an average is the average of the standard deviations.
  meanVar. <- tapply(object$V[ist,ist,], factor., mean)
  meanSD. <- tapply(sqrt(object$V[ist,ist,]), 
                      factor., mean)
  meanVar <- (1-cor.)*meanVar.+cor.*(meanSD.^2)
  meanSD <- sqrt(meanVar)
#
  tabfac <- table(factor.)
  t. <- (facState-meanState)/meanSD 
  p. <- 2*pnorm(-abs(t.))
# variance estimated using all the data, 
# not just those within each presidency, 
# so dft = (total obs) - nSt
  dfe <- (nrow(object$alphahat) - nSt)
  st2 <- qt(1-.5*(1-conf), dfe) * meanSD
  st2. <- st2 %o% c(lower=-1, upper=1)
  confInt <- as.numeric(facState) + st2.
#
  Exec <- ordered(names(facState), names(facState))
  stateSum <- cbind(data.frame(Exec=Exec, 
          n=as.numeric(tabfac),
          mean=as.numeric(facState), 
          stdError=as.numeric(meanSD),
          t.=as.numeric(t.), 
          p_value=as.numeric(p.)), confInt)
  names(stateSum)[c(1, 3)] <- c(factorName, state)
# 
  chisq. <- sum(t.^2)
  F.. <- (chisq./(nSt-1))
  F. <- c(F=F.., df1=nSt-1, df2=dfe, 
          p=pf(chisq., nSt, dfe, lower=FALSE))
#  print(F.)
  attr(stateSum, 'F') <- F.
#
  stateSum
}
```

line 699 stateByFactor

```{r, echo=FALSE}
EWMA2pres2sum <- stateByFactor(EWMA2pres2.KFS)
suppressMessages(library(ggplot2))

# DON'T PLOT EWMA2pres2sum here
# Instead plot EWMA2pres3sum below 

#EWMA2pres2fit$optim.out$par
#exp(EWMA2pres2fit$optim.out$par[-1]/2)

EWMA2pres2.rstd <- rstandard(EWMA2pres2.KFS)

a1.3a <- c(level=log(GDP$realGDPperCapita[1]), slope=0, 
           pres3=0)
```

line 717 after a1.3a

```{r, echo=FALSE}
EWMA2pres3P1 <- diag(c(0, 0, NA))
EWMA2pres3P1inf <- diag(c(1, 1, 0))
EWMA2pres3fmla <- log(realGDPperCapita) ~ 
  SSMtrend(3, Q = list(level=matrix(NA), slope=matrix(NA),
          pres3=EWMA2pres1Q.slope), 
      P1=EWMA2pres3P1, P1inf=EWMA2pres3P1inf, a1=a1.3a, 
      ynames='logGDPperCap') 

EWMA2pres3mdl. <- SSModel(EWMA2pres3fmla, GDP,
                          H=matrix(NA))
EWMA2pres3mdl <- fixModelNames(EWMA2pres3mdl., 
                    names(a1.3a), 'logGDPperCap' )
```

LINE 734 after EWMA2pres3mdl

```{r, echo=FALSE}
pres3states <- names(a1.3a)
pres3T <- array(EWMA2pres3mdl$T, dim=c(3,3,N), 
        dimnames=list(pres3states, pres3states,
                      GDP$Year) )
pres3T[1,3,] <- 1
pres3T[2,3,] <- 0 
pres3T[3,3, presLastYr] <- 0

EWMA2pres3mdl$T <- pres3T 

attr(EWMA2pres3mdl, 'tv') <- c(Z=0L, H=0L, 
                               T=1L, R=0L, Q=1L)

#EWMA2pres2fit$optim.out$par
EWMA2pres3init <- rep(
        EWMA2pres2fit$optim.out$par[2], 4)
names(EWMA2pres3init) <- c("lnQ.lvl", "lnQ.slope", 
        "lnQ.pres3", "lnH")
#EWMA2pres3init
```

LINE 758 in EWMA2pres3

```{r, echo=FALSE}
EWMA2pres3updt <- function(pars=EWMA2pres3init, 
                      model=EWMA2pres3mdl, ...){
  vars <- exp(pars)
  Q <- model$Q
  Q[1,1,] <- vars[1]
  Q[2,2,] <- vars[2]
  Q[3,3,presLastYr] <- vars[3]
  model$Q <- Q
  model$P1[3,3] <- vars[3]
  model$H[] <- vars[4]
  model
}

EWMA2pres3fit <- fitSSM(EWMA2pres3mdl,
                    inits=EWMA2pres3init, 
                        updatefn=EWMA2pres3updt) 

logLiks[5, 2:6] <- logLik2(EWMA2pres3fit)

logLiks[5, 7:9] <- c('y', '-', 'EWMA2')
logLR2p3 <- apply(logLiks[c(2, 5), 2:4], 2, diff)
logLiks[5, 10] <- signif(pchisq(2*logLR2p3[3], 1, 
                         lower=FALSE), 2)
#logLiks[1:5,]

EWMA2pres3.KFS <- KFS(EWMA2pres3fit$model)

#EWMA2pres3fit$optim.out$par
#exp(EWMA2pres3fit$optim.out$par/2)
#apply(EWMA2pres3.KFS$alphahat, 2, range)

EWMA2pres3sum <- stateByFactor(EWMA2pres3.KFS,
                                "pres3")

# 6.  EWMA2 with a fixed effect for war 
a1.4 <- c(level=log(GDP$realGDPperCapita[1]), slope=0, 
           war=0, deaths=0)
EWMA2war0fmla <- log(realGDPperCapita) ~ 
    SSMtrend(4, Q = list(level=matrix(NA),
        slope=matrix(NA), war=matrix(0),
        deaths=matrix(0)), a1=a1.4,
           ynames='lnGDPperCap') 
EWMA2war0mdl. <- SSModel(EWMA2war0fmla, GDP,
                         H=matrix(NA))

EWMA2war0mdl <- fixModelNames(EWMA2war0mdl., 
                  names(a1.4), 'logGDPperCap' )

warStates <- names(a1.4)
war0T <- array(diag(4), dim=c(4,4,N), 
    dimnames=list(warStates, warStates, GDP$Year))
war0T[1, 2,] <- 1  
war0T[1, 3,] <- (GDP$war!='')
war0T[1, 4,] <- GDP$battleDeathsPMP

EWMA2war0mdl$T <- war0T 

attr(EWMA2war0mdl, 'tv') <- c(Z=0L, H=0L, 
                          T=1L, R=0L, Q=0L)

EWMA2war0fit <- fitSSM(EWMA2war0mdl, inits=EWMA2init)
logLiks[6, 2:6] <- logLik2(EWMA2war0fit)
logLiks[6, 7:9] <- c('y', '-', 'EWMA2') 

logLR2w0 <- apply(logLiks[c(2, 6), 2:4], 2, diff)
logLiks[6, 10] <- signif(pchisq(2*logLR2w0[3], 2, 
                         lower=FALSE), 2)
#logLiks[1:6,]

EWMA2war0fit2 <- fitSSM(EWMA2war0mdl, 
                       inits=EWMA2fit$optim.out$par)
#logLik2(EWMA2war0fit2)
#The same as before.  

#As a further check on the code we used, we should get #the same answer as from EWMA2 if we set the war #components of P1inf to 0:  

EWMA2war0mdl3 <- EWMA2war0mdl 
war0P1inf <- diag(c(1, 1, 0, 0))
dimnames(war0P1inf) <- list(warStates, warStates)
EWMA2war0mdl3$P1inf <- war0P1inf
EWMA2war0fit3 <- fitSSM(EWMA2war0mdl3, inits=EWMA2init)
#logLik2(EWMA2war0fit3)
# same as EWMA2, as we expected.  

beforeWar <- which(c(
    head(GDP$war, -1)=='' & tail(GDP$war, -1)!=''),
    FALSE)
#GDP[beforeWar[1]+0:1,]

EWMA2warQ <- array(0, c(4,4,N), 
    dimnames=list(warStates, warStates, GDP$Year))
EWMA2warQ[1,1,] <- NA
EWMA2warQ[2,2,] <- NA
EWMA2warQ[3:4,3:4,beforeWar] <- NA 

#EWMA2warQ[,,beforeWar[1]+(-1):1]

EWMA2war1mdl <- EWMA2war0mdl
EWMA2war1mdl$Q <- EWMA2warQ
attr(EWMA2war1mdl, 'tv')[5] <- 1L

EWMA2war1mdl$P1inf <- diag(c(1,1,0,0))

war1T <- war0T
war1T[3:4, 3:4, GDP$war==''] <- 0
#war1T[,,c(1:2, 8, 22:24)]

EWMA2war1mdl$T <- war1T

EWMA2war1init <- 
    c(1, 1, .5, .5, 0, 1) * 
  rep(EWMA2fit$optim.out$par[1], 6)
names(EWMA2war1init) <- c('lnQ.lvl', 'lnQ.slope', 
      'lnQ.war', 'lnQ.deaths', 'lnQ.warDeaths', 'lnH')
#EWMA2war1init
EWMA2war1updt <- function(pars=EWMA2war1init, 
                      model=EWMA2war1mdl, ...){
  Q <- model$Q
  Q[1,1,] <- exp(pars[1])
  Q[2,2,] <- exp(pars[2])
#  
  P1w <- as.matrix(nlme::pdLogChol(pars[3:5]))
  model$P1[3:4, 3:4] <- P1w
  Q[3:4, 3:4, beforeWar] <- P1w
  model$Q <- Q
#  
  model$H[] <- exp(pars[6])
  model
} 
EWMA2war1fit <- fitSSM(EWMA2war1mdl,
    inits=EWMA2war1init, updatefn=EWMA2war1updt)
#logLiks[1:6,1:5]
#logLik2(EWMA2war1fit)[1:4]

EWMA2war1init0 <- EWMA2war1init
EWMA2war1init0[c(1, 2, 6)] <- EWMA2fit$optim.out$par
EWMA2war1init0[3:5] <- c(-999, -999, 0)
EWMA2war1fit0 <- fitSSM(EWMA2war1mdl,
                        inits=EWMA2war1init0, 
                        updatefn=EWMA2war1updt)
#logLik2(EWMA2war1fit0)[1:4]

EWMA2war1init2 <- exp(EWMA2war1init/
        c(2, 2, 1, 1, 1, 2))
EWMA2war1init2[5] <- 0
names(EWMA2war1init2) <- c('Q.lvl', 'Q.slope', 
    'Q.war', 'Q.deaths', 'Q.warDeaths', 'H')
#EWMA2war1init2
EWMA2war1updt2 <- function(pars=EWMA2war1init2,
              model=EWMA2war1mdl, ...){
  Q <- model$Q
  Q[1,1,] <- pars[1]^2
  Q[2,2,] <- pars[2]^2
# 
  C1w. <- matrix(c(1, pars[5], pars[5], 1), 2)
  P1w. <- (C1w.*outer(pars[3:4], pars[3:4]))
#  
  model$P1[3:4, 3:4] <- P1w.
  Q[3:4, 3:4, beforeWar] <- P1w.
  model$Q <- Q
#  
  model$H[] <- pars[6]^2
  model
} 

# Confirm that the two functions 
# produce the same model
# from comparable 
EWMA2war1mdl1.0 <- EWMA2war1updt()
EWMA2war1mdl2.0 <- EWMA2war1updt2()
#all.equal(EWMA2war1mdl1.0, EWMA2war1mdl2.0)

# lower and upper limits 
EWMA2war1l <- rep(0, 6)
EWMA2war1l[5] <- (-1)
names(EWMA2war1l) <- names(EWMA2war1init2)
#EWMA2war1l
EWMA2war1u <- rep(Inf, 6)
EWMA2war1u[5] <- 1
names(EWMA2war1u) <- names(EWMA2war1init2)
#EWMA2war1u
EWMA2war1fit2 <- fitSSM(EWMA2war1mdl,
    inits=EWMA2war1init2, 
    updatefn=EWMA2war1updt2, method = "L-BFGS-B", 
    lower=EWMA2war1l, upper=EWMA2war1u)
logLiks[7, 2:6] <- logLik2(EWMA2war1fit2)

logLiks[7, 7:9] <- c('n', 'y', 'EWMA2') 

logLR2w1 <- apply(logLiks[c(2, 7), 2:4], 2, diff)
logLiks[7, 10] <- signif(pchisq(2*logLR2w1[3], 1, 
                         lower=FALSE), 2)
#logLiks[1:7, 1:5]
#The marginal logLik now matches EWMA2.  

EWMA2war2mdl <- EWMA2mdl
EWMA2war2Q <- array(EWMA2mdl$Q, dim=c(2,2,N), 
    dimnames=list(names(a1.2), names(a1.2), GDP$Year))
#EWMA2war2Q[,, 1:2]

EWMA2war2mdl$Q <- EWMA2war2Q
attr(EWMA2war2mdl, 'tv') <- 
        c(Z=0L, H=0L, T=0L, R=0L, Q=1L)

EWMA2war2init <- c(1, 0, 0, 1, 1) * 
  EWMA2fit$optim.out$par[1]
names(EWMA2war2init) <- c('lnQ.lvl', 'lnQ.lvl.war',
                'lnQ.lvl.deaths', 'lnQ.slope', 'lnH')
#EWMA2war2init

EWMA2war2updt <- function(pars=EWMA2war2init, 
                      model=EWMA2war2mdl, ...){
#
  Q <- model$Q
  lnQ11 <- (pars[1] + pars[2]*(GDP$war!='') +
                   pars[3]*GDP$battleDeathsPMP)
  Q11 <- exp(lnQ11)
  oops <- which(!is.finite(Q11))
  Q11[oops] <- .Machine$double.xmax
#  
#  noops <- length(oops)
#  if(noops>0){
#    cat('Q[1,1] NA or Inf with pars =\n')
#    print(pars)
#    stop('Problem occurs ', noops, ' times, ', 
#         'starting with number ', noops[1], 
#         ' for which Q[1,1] = ', Q11[oops[1]])
#  }
  Q[1,1,] <- Q11
#
  Q22 <- exp(pars[4])
  if(!is.finite(Q22)){
    print(pars)
    stop('Q22 = ', Q22)
  }
  
  Q[2,2,] <- Q22
  model$Q <- Q
#  
  model$H[] <- exp(pars[5])
  model
} 
#EWMA2war2updt()

EWMA2war2fit <- fitSSM(EWMA2war2mdl,
    inits=EWMA2war2init, updatefn=EWMA2war2updt)
#logLik2(EWMA2war2fit)
# did not converge
# try a constrained optimization over standard
# deviations for this, as with EWMA2war1 above.  

EWMA2war2init2 <- exp(EWMA2war2init/2)
EWMA2war2init2[2:3] <- 0 
names(EWMA2war2init2) <- c('sQ.lvl', 'lnQ.lvl.war',
                'lnQ.lvl.deaths', 'sQ.slope', 'sH')

EWMA2war2updt2 <- function(pars=EWMA2war2init2, 
                      model=EWMA2war2mdl, ...){
#
  Q <- model$Q
  Q11 <- ((pars[1]^2)*exp(pars[2]*(GDP$war!='') +
                   pars[3]*GDP$battleDeathsPMP))
  oops <- which(!is.finite(Q11))
  Q11[oops] <- .Machine$double.xmax
#  
#  noops <- length(oops)
#  if(noops>0){
#    cat('Q[1,1] NA or Inf with pars =\n')
#    print(pars)
#    stop('Problem occurs ', noops, ' times, ', 
#         'starting with number ', noops[1], 
#         ' for which Q[1,1] = ', Q11[oops[1]])
#  }
  Q[1,1,] <- Q11
#
  Q22 <- pars[4]^2
  if(!is.finite(Q22)){
    print(pars)
    stop('Q22 = ', Q22)
  }
  
  Q[2,2,] <- Q22
  model$Q <- Q
#  
  model$H[] <- (pars[5]^2)
  model
} 

EWMA2war2fit2 <- fitSSM(EWMA2war2mdl,
    inits=EWMA2war2init2, updatefn=EWMA2war2updt2)
logLiks[8, 2:6] <- logLik2(EWMA2war2fit2)
logLiks[8, 7:9] <- c('n', 'y', 'EWMA2') 
logLR2w2 <- apply(logLiks[c(2, 8), 2:4], 2, diff)
logLiks[8, 10] <- signif(pchisq(2*logLR2w2[3], 
    logLR2w2[1],lower=FALSE), 2)
# best fitting war model so far 
# but still not statistically significant

# unemployment? 
unemp1 <- with(GDP, 
               unemployment[!is.na(unemployment)][1])
uEWMA1fmla <- qnorm(unemployment) ~
        SSMtrend(1,Q=list(matrix(NA)),
                 a1 = qnorm(unemp1),
                 ynames='probitUnemp' ) 

uEWMA1mdl. <-SSModel(uEWMA1fmla, GDP, H=matrix(NA) )
uEWMA1mdl <- fixModelNames(uEWMA1mdl., 
                      'unempLvl', 'probitUnemp')

uEWMA1fit <- fitSSM(uEWMA1mdl, inits=c(lnQ=0, lnH=0))

#uEWMA1pred <- predict(uEWMA1fit$model, 
#              interval='prediction', filtered=TRUE)
#ylim <- range(qnorm(GDP$unemployment), na.rm=TRUE)
#plotPresWars(qnorm(unemployment), GDP, ... 

logLiks[9, 2:6] <- logLik2(uEWMA1fit)
logLiks[9, 7:9] <- c('n', '-', '') 

#uEWMA1.KFS <- KFS(uEWMA1fit$model)
#uEWMA1.rstd <- rstandard(uEWMA1.KFS)

#ylim.std <- range(uEWMA1.rstd, na.rm=TRUE)

uEWMA1H <- array(NA, c(1, 1, N), 
  dimnames=list('probitUnemp', 'probitUnemp',
                GDP$Year))

uEWMA1aMdl. <-SSModel(uEWMA1fmla, GDP, H=uEWMA1H)
uEWMA1aMdl <- fixModelNames(uEWMA1aMdl., 'level', 
                    'probitUnemp')

uEWMA1aInit <- rep(0, 5)
names(uEWMA1aInit) <- c('lnQ', paste0('lnH', 1:4))
uEWMA1aUpdt <- function(pars=uEWMA1aInit,
      model=uEWMA1aMdl, ...){
  vars <- exp(pars)
  Q <- model$Q
  Q[1,1,] <- vars[1]
  model$Q <- Q
#
  Yrs <- time(uEWMA1mdl$y)
  H <- (vars[5]+(Yrs<1940)*vars[4] + 
          (Yrs<1931)*vars[3]+(Yrs<1890)*vars[2])
  model$H[] <- H
  model
} 

uEWMA1aFit <- fitSSM(uEWMA1aMdl, inits=uEWMA1aInit, 
                     updatefn=uEWMA1aUpdt)

uEWMA1aMdlEst <- uEWMA1aUpdt(uEWMA1aFit$optim.out$par)
uEWMA1aH. <- uEWMA1aMdlEst$H
uEWMA1aH <- ts(as.numeric(uEWMA1aH.), 1790)

uEWMA1a1Init <- rep(1, 5)
names(uEWMA1a1Init) <- c('Q', paste0('H', 1:4))
uEWMA1a1Updt <- function(pars=uEWMA1a1Init, 
      model=uEWMA1aMdl, ...){
  vars <- (pars^2)
  Q <- model$Q
  Q[1,1,] <- vars[1]
  model$Q <- Q
#
  Yrs <- time(uEWMA1mdl$y)
  H <- (vars[5]+(Yrs<1940)*vars[4] + 
          (Yrs<1931)*vars[3]+(Yrs<1890)*vars[2])
  model$H[] <- H
  model
} 

uEWMA1a1Fit <- fitSSM(uEWMA1aMdl, inits=uEWMA1a1Init, 
                     updatefn=uEWMA1a1Updt, 
                     method="L-BFGS-B", lower=0)

logLiks[10, 2:6] <- logLik2(uEWMA1a1Fit)

logLiks[10, 7:9] <- c('n', 'y', 'uEWMA1') 
logLRu1a1 <- apply(logLiks[c(9, 10), 2:4], 2, diff)
logLiks[10, 10] <- signif(pchisq(2*logLRu1a1[3], 
    logLRu1a1[1],lower=FALSE), 2)

uEWMA1a1MdlEst <-
  uEWMA1a1Updt(uEWMA1a1Fit$optim.out$par)

uEWMA1a.KFS <- KFS(uEWMA1a1Fit$model)
uEWMA1a.rstd <- rstandard(uEWMA1a.KFS)

a1.2u <- c(level=qnorm(unemp1), pres3=0)
uPres3states <- names(a1.2u)

uEWMA1pres3P1 <- diag(c(0, NA))
uEWMA1pres3P1inf <- diag(c(1, 0))
uEWMA1pres3fmla <- qnorm(unemployment) ~ 
  SSMtrend(2, Q = list(level=matrix(NA),
            pres3=EWMA2pres1Q.slope), 
      P1=uEWMA1pres3P1, P1inf=uEWMA1pres3P1inf,
      a1=a1.2u, ynames='probitUnemp') 

uEWMA1pres3mdl. <- SSModel(uEWMA1pres3fmla, GDP, 
                           H=uEWMA1H)
uEWMA1pres3mdl <- fixModelNames(uEWMA1pres3mdl., 
                      uPres3states, 'probitUnemp')

uPres3T <- array(uEWMA1pres3mdl$T, dim=c(2,2,N), 
        dimnames=list(uPres3states, uPres3states,
                      GDP$Year) )
uPres3T[2,2, presLastYr] <- 0

uEWMA1pres3mdl$T <- uPres3T 

attr(uEWMA1pres3mdl, 'tv') <- c(Z=0L, 
                  H=1L, T=1L, R=0L, Q=1L)

uEWMA1pres3init <- rep(uEWMA1aFit$optim.out$par, 
                       c(2, rep(1, 4)))
names(uEWMA1pres3init)[1:2] <- c("lnQ.lvl",
                                 "lnQ.pres3")

uEWMA1pres3updt <- function(pars=uEWMA1pres3init, 
                      model=uEWMA1pres3mdl, ...){
  vars <- exp(pars)
  Q <- model$Q
  Q[1,1,] <- vars[1]
  model$P1[2,2] <- vars[2]
  Q[2,2,presLastYr] <- vars[2]
  model$Q <- Q
#
  Yrs <- time(uEWMA1mdl$y)
  H <- (vars[6]+(Yrs<1940)*vars[5] + 
          (Yrs<1931)*vars[4]+(Yrs<1890)*vars[3])
  model$H[] <- H
  model
}

uEWMA1pres3fit <- fitSSM(uEWMA1pres3mdl,
    inits=uEWMA1pres3init, updatefn=uEWMA1pres3updt) 
#logLik2(uEWMA1pres3fit)

uEWMA1pres3Cinit <- exp(uEWMA1pres3fit$optim.out$par/2)
names(uEWMA1pres3Cinit) <- sub('^ln', 's', 
                    names(uEWMA1pres3init))

uEWMA1pres3Cupdt <- function(pars=uEWMA1pres3Cinit, 
                      model=uEWMA1pres3mdl, ...){
  vars <- (pars^2)
  Q <- model$Q
  Q[1,1,] <- vars[1]
  model$P1[2,2] <- vars[2]
  Q[2,2,presLastYr] <- vars[2]
  model$Q <- Q
#
  Yrs <- time(uEWMA1mdl$y)
  H <- (vars[6]+(Yrs<1940)*vars[5] + 
          (Yrs<1931)*vars[4]+(Yrs<1890)*vars[3])
  model$H[] <- H
  model
}

uEWMA1pres3Cfit <- fitSSM(uEWMA1pres3mdl,
    inits=uEWMA1pres3Cinit, updatefn=uEWMA1pres3Cupdt, 
    method="L-BFGS-B", lower=0) 

logLiks[11, 2:6] <- logLik2(uEWMA1pres3Cfit)

logLiks[11, 7:9] <- c('y', 'y', 'uEWMA1a') 
logLRu1p3 <- apply(logLiks[c(10, 11), 2:4], 2, diff)
logLiks[11, 10] <- signif(pchisq(2*logLRu1p3[3], 
    logLRu1p3[1],lower=FALSE), 2)

a1.3u <- c(level=qnorm(unemp1), war=0, deaths=0)
uWarStates <- names(a1.3u)

uEWMA1war0fmla <- qnorm(unemployment) ~ 
    SSMtrend(3, Q = list(level=matrix(NA), 
                war=matrix(0), deaths=matrix(0)), 
        a1=a1.3u, ynames='probitUnemp') 

uEWMA1war0mdl. <- SSModel(uEWMA1war0fmla, GDP,
                          H=uEWMA1H)
uEWMA1war0mdl <- fixModelNames(uEWMA1war0mdl., 
                  uWarStates, 'probitUnemp')

uWar0T <- array(diag(3), dim=c(3,3,N), 
    dimnames=list(uWarStates, uWarStates, GDP$Year))
uWar0T[1, 2,] <- (GDP$war!='')
uWar0T[1, 3,] <- GDP$battleDeathsPMP

uEWMA1war0mdl$T <- uWar0T 

attr(uEWMA1war0mdl, 'tv') <- c(Z=0L, 
                H=1L, T=1L, R=0L, Q=0L)

uEWMA1war0init <- rep(uEWMA1aFit$optim.out$par[
            c(1, 3)], c(1, 4))
names(uEWMA1war0init) <-
      names(uEWMA1aFit$optim.out$par)

uEWMA1war0updt <- function(pars=uEWMA1war0init, 
                      model=uEWMA1war0mdl, ...){
  vars <- exp(pars)
  Q <- model$Q
  Q[1,1,] <- vars[1]
  model$Q <- Q
#
  Yrs <- time(uEWMA1mdl$y)
  H <- (vars[5]+(Yrs<1940)*vars[4] + 
          (Yrs<1931)*vars[3]+(Yrs<1890)*vars[2])
  model$H[] <- H
  model
}

uEWMA1war0fit <- fitSSM(uEWMA1war0mdl,
    inits=uEWMA1war0init, uEWMA1war0updt)

uEWMA1war0Cinit <- exp(uEWMA1war0fit$optim.out$par/2)
names(uEWMA1war0Cinit) <- sub('ln', 's', 
                              names(uEWMA1war0Cinit))
uEWMA1war0Cupdt <- function(pars=uEWMA1war0Cinit, 
                      model=uEWMA1war0mdl, ...){
  vars <- (pars^2)
  Q <- model$Q
  Q[1,1,] <- vars[1]
  model$Q <- Q
#
  Yrs <- time(uEWMA1mdl$y)
  H <- (vars[5]+(Yrs<1940)*vars[4] + 
          (Yrs<1931)*vars[3]+(Yrs<1890)*vars[2])
  model$H[] <- H
  model
}

uEWMA1war0Cfit <- fitSSM(uEWMA1war0mdl, 
      inits=uEWMA1war0Cinit, uEWMA1war0Cupdt,
      method="L-BFGS-B", lower=0)

logLiks[12, 2:6] <- logLik2(uEWMA1war0Cfit)

logLiks[12, 7:9] <- c('y', 'y', 'uEWMA1a') 
logLRu1w0 <- apply(logLiks[c(10, 12), 2:4], 2, diff)
logLiks[12, 10] <- signif(pchisq(2*logLRu1w0[3], 
    logLRu1w0[1],lower=FALSE), 2)

uEWMA1warQ <- array(0, c(3,3,N), 
    dimnames=list(uWarStates, uWarStates, GDP$Year))
uEWMA1warQ[1,1,] <- NA
uEWMA1warQ[2:3,2:3,beforeWar] <- NA 

#uEWMA1warQ[,,beforeWar[1]+(-1):1]

uEWMA1war1mdl <- uEWMA1war0mdl
uEWMA1war1mdl$Q <- uEWMA1warQ
attr(uEWMA1war1mdl, 'tv')[5] <- 1L

uEWMA1war1mdl$P1inf <- diag(c(1,0,0))

uWar1T <- uWar0T
uWar1T[2:3, 2:3, GDP$war==''] <- 0

uEWMA1war1mdl$T <- uWar1T

uEWMA1war1init <- c(lnQ=-2.66, lnQ.war=-1,
    lnQ.deaths=-1, lnQ.warDeaths=0, lnH1=-4, 
    lnH2=-4, lnH3=-4, lnH4=-4)

uEWMA1war1updt <- function(pars=uEWMA1war1init, 
                      model=uEWMA1war1mdl, ...){
  Q <- model$Q
  Q[1,1,] <- exp(pars[1])
#  
  P1w <- as.matrix(nlme::pdLogChol(pars[2:4]))
  model$P1[2:3, 2:3] <- P1w
  Q[2:3, 2:3, beforeWar] <- P1w
  model$Q <- Q
# 
  Yrs <- time(uEWMA1mdl$y)
  H <- (exp(pars[8])+(Yrs<1890)*exp(pars[7]) +
      (Yrs<1931)*exp(pars[6])+(Yrs<1890)*exp(pars[5]))
  model$H[] <- H 
  model
} 

uEWMA1war1fit <- fitSSM(uEWMA1war1mdl,
        inits=uEWMA1war1init, 
        updatefn=uEWMA1war1updt)

uEWMA1war1Cinit <- exp(uEWMA1war1init)
names(uEWMA1war1Cinit) <- sub('ln', 's', 
                  names(uEWMA1war1init))
uEWMA1war1Cinit[4] <- 0 
names(uEWMA1war1Cinit)[4] <- 'rQ.warDeaths' 

uEWMA1war1Cupdt <- function(pars=uEWMA1war1Cinit, 
                      model=uEWMA1war1mdl, ...){
  vars <- pars^2
  Q <- model$Q
  Q[1,1,] <- vars[1]
#  
  C1w <- matrix(rep(pars[4], 4), 2,2) 
  diag(C1w) <- 1
  P1w <- (C1w * outer(pars[2:3], pars[2:3]))
  model$P1[2:3, 2:3] <- P1w
  Q[2:3, 2:3, beforeWar] <- P1w
  model$Q <- Q
# 
  Yrs <- time(uEWMA1mdl$y)
  H <- (vars[8]+(Yrs<1890)*vars[7] +
      (Yrs<1931)*vars[6]+(Yrs<1890)*vars[5])
  model$H[] <- H 
  model
} 

uEWMA1war1l <- uEWMA1war1Cinit
uEWMA1war1l[] <- 0
uEWMA1war1l[4] <- (-1)
uEWMA1war1u <- uEWMA1war1Cinit
uEWMA1war1u[] <- Inf
uEWMA1war1u[4] <- 1

uEWMA1war1Cfit <- fitSSM(uEWMA1war1mdl,
    inits=uEWMA1war1Cinit, updatefn=uEWMA1war1Cupdt,
    method="L-BFGS-B", 
    lower=uEWMA1war1l, upper=uEWMA1war1u)
logLiks[13, 2:6] <- logLik2(uEWMA1war1Cfit)

logLiks[13, 7:9] <- c('n', 'y', 'uEWMA1a') 
logLRu1w1 <- apply(logLiks[c(10, 13), 2:4], 2, diff)
logLiks[13, 10] <- signif(pchisq(2*logLRu1w1[3], 
    logLRu1w1[1],lower=FALSE), 2)

# Okun's law 

OkunDat <- cbind(lnGDPperCap=log(GDP$realGDPperCapita),
           probitUnemp=qnorm(GDP$unemployment))
OkunVars <- colnames(OkunDat)

OkunStates <- c('GDP.lvl', 'unemp.lvl', 'GDP.slope')
OkunZ <- array(c(1, 0, 0, 1, 0, 0), dim=c(2, 3, 1), 
    dimnames=list(OkunVars, OkunStates, NULL) ) 
              
OkunT <- array(c(1, 0, 0, 0, 1, 0, 1, 0, 1), 
    dim=c(3, 3, 1), 
    dimnames=list(OkunStates, OkunStates, NULL) )

OkunQ <- array(c(NA, NA, 0, NA, NA, NA, 0, NA, NA), 
    dim=c(3, 3, 1), 
    dimnames=list(OkunStates, OkunStates, NULL))

Okun.a1 <- c(apply(OkunDat, 2, 
      function(x)x[!is.na(x)][1]), 0) 
names(Okun.a1) <- OkunStates

OkunP1 <- diag(0, 3)
dimnames(OkunP1) <- list(OkunStates, OkunStates)
OkunP1inf <- OkunP1
diag(OkunP1inf) <- 1

OkunFmla <- formula(OkunDat ~ -1 + SSMcustom(
  Z=OkunZ, T=OkunT, Q=OkunQ, a1=Okun.a1, 
  P1=OkunP1, P1inf=OkunP1inf, index=1:2, n=N,
  state_names=OkunStates) )

OkunH <- array(diag(NA, 2), dim=c(2, 2, N), 
    dimnames=list(OkunVars, OkunVars, GDP$Year) )

OkunMdl. <- SSModel(OkunFmla, H=OkunH)
OkunMdl <- fixModelNames(OkunMdl., OkunStates, 
                  OkunVars)

OkunInit <- rep(0, 10)
names(OkunInit) <- c("lnQ.pl", "lnQ.ul", "lnQ.ps", 
  "lnQ.pl.ul", "lnQ.ul.ps", "lnHp", "lnHu1", 
  "lnHu2", 'lnHu3', 'lnHu4')
OkunInit[c(1, 3, 6)] <- EWMA2fit$optim.out$par[1]
OkunInit[c(2, 7:10)] <- rep(
  uEWMA1aFit$optim.out$par[c(1, 3)], c(1, 4))

pdLogChol3.5 <- function(value, ...){
  v6 <- c(value[1:4], 0, value[5])
  nlme::pdLogChol(v6)
}

OkunUpdt <- function(pars=OkunInit, 
                     model=OkunMdl, ...){
#  
  Q <- pdLogChol3.5(pars) 
  model$Q[,,] <- as.matrix(Q)
# 
  Yrs <- time(model$y)
  H <- model$H
  vars <- exp(pars)
  H[1,1,] <- vars[6]
#  
  Yrs <- time(uEWMA1mdl$y)
  Hu <- (vars[10]+(Yrs<1890)*vars[9] +
      (Yrs<1931)*vars[8]+(Yrs<1890)*vars[7])
  H[2,2,] <- Hu
  model$H[] <- H 
  model
}

OkunFit <- fitSSM(OkunMdl, OkunInit, OkunUpdt)
logLiks[14, 2:6] <- logLik2(OkunFit)

logLiks[14, 7:9] <- c('y', '-', '') 

logLiks[, c(1:2, 4, 5:10)]
logLiks[, c(1:2, 4, 7:10)]

OkunFit$optim.out$par
```

Unfortunately, "Computation of marginal likelihood failed", and the diffuse likelihood for this case cannot be compared with any of the previous models.  The rmse.lnUSD was better than EWMA1 but slightly worse than EWMA2:  0.0429 vs. 0.0456 and 0.0427.  However, the rmse.pbtUnemp was substantially lower than the best previous model:  0.268 vs. 0.283 for uEWMA1a and 0.284 for uEWMA1war0.  

What are the paramter estimates and the resulting correlations in Q?  

```{r}
OkunFit$optim.out$par
(OkunQ1.3 <- pdLogChol3.5(OkunFit$optim.out$par))
cov2cor(as.matrix(OkunQ1.3))
```

Wow:  The correlation between the increments in GDP.lvl and unemp.lvl is -0.999997.  The literature on Okun's Law says that the increments in GDP and unemployment are often cointegrated, e.g.,  `r Citet(bib2, "Lee2000")`, and negatively correlated.  Moreover the correlation between the increments in GDP.lvl and GDP.slope is estimated at -0.002 -- virtually zero.  

This suggests we modify this model to estimate only 6 parameters, not 8, and force those 2 correlations to -1 and 0, respectively.  We'll call this a separate model:  Okun1.  


```

# SEE AverageIncomeModelsPlus.Rmd for the rest ... 
```

The p.values in this table were obtained by using [Wilks's theorem](https://en.wikipedia.org/wiki/Likelihood-ratio_test#Distribution:_Wilks.27s_theorem) to compare the marginal likelihood of the model in that row with the reference model.  The likelihood ratio in this test is "most powerful", per the [Neyman–Pearson lemma](https://en.wikipedia.org/wiki/Neyman%E2%80%93Pearson_lemma).

Unfortunately, Wilk's theorem does not apply when the null hypothesis is on a boundary, as with a variance parameter at 0.  In that case, the likelihood ratio is still most powerful, but twice the log(likelihood ratio) may not be approximately chi-square.  `r Citet(bib2, "PinBates")` recommend simulation to estimate p-values.  They provide simulations that suggest that in cases like these, the p-values per Wilk's theorem tend to be larger than the actual (simulated) p-values by factors ranging from 1 to 3. If that's accurate for these cases, then a nominal p-value of 0.05 means that it likely is significant at that level, which a nominal p-value of 0.10 says that it might be significant at the 0.05 level but not at the 0.02 level, for example.  



# President effect on GDP 



* Discuss war effect on GDP 


# Unemployment and war 




# Okun's law 




# Future work 




# References
```{r results = "asis", echo = FALSE}
PrintBibliography(bib2)
```
